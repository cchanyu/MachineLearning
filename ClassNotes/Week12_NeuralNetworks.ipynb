{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week12_NeuralNetworks",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twdwz57JtAz9"
      },
      "source": [
        "# Week 12 \n",
        "# Introduction to Neural Networks\n",
        "\n",
        "Slides can be found [here](https://drive.google.com/file/d/1Ae5ancx-CW1eah51cNgKzfu87VDUTK_n/view?usp=sharing)\n",
        "\n",
        "**Training large neural networks requires a lot of calculation.** Please turn on GPU computing from \"Edit\" -> \"Notebook Setting\" -> \"Hardware Acceleration\" before running the code below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYcVCgQFtGeL"
      },
      "source": [
        "# Build a Classifier for Hand-Written Digits\n",
        "\n",
        "Adapted from [TensorFlow tutorial](https://www.tensorflow.org/tutorials/quickstart/beginner)\n",
        "\n",
        "1. Build a neural network that classifies images.\n",
        "2. Train this neural network.\n",
        "3. Evaluate the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4Oo-6KAtGgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e28e9be-924c-4a86-f0e8-bebcad062ddd"
      },
      "source": [
        "# import tensorflow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "# Make numpy values easier to read.\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrEKfS4ttGjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe69d26-8c08-4b7e-bc74-2b19b90d3cda"
      },
      "source": [
        "# Load and prepare the MNIST dataset.\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Convert the data from integers to floating-point numbers\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yk_3tRYtGl5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "d70f1aa4-666b-4a15-b6be-0cf97d6543cb"
      },
      "source": [
        "# extract the first image in x_train\n",
        "idx = 0\n",
        "img = x_train[idx, :, :] # : means that we include all indices\n",
        "print(\"Shape of the image:\", img.shape)\n",
        "plt.imshow(img, cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the image: (28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff96a06c3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTFUQ89HtGou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a6dbb23-e665-4310-c662-55876ac1ca5a"
      },
      "source": [
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "y_train[idx]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of y_train: (60000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP0iuV3etGq5"
      },
      "source": [
        "import tensorflow.keras as K # A common abbrevation of the kera package.\n",
        "# Build a neural network model by stacking layers.\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)), # convert a 28*28 matrix into a 784 1D array\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)                                   \n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy0vfyIztGtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919212e6-373a-4428-faa6-b8167982218c"
      },
      "source": [
        "# For each example the model returns a vector of \"logits\", one for each class.\n",
        "index = 123\n",
        "predictions = model(x_train[index:(index+1)]).numpy()\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.221  0.518 -0.155  0.288  0.178 -0.396  0.288  0.061 -0.129 -0.511]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hAz6sqPtGwF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe858d3e-3663-40e2-c0f6-9e3c793c413c"
      },
      "source": [
        "# The tf.nn.softmax function converts these logits to probabilities for each class\n",
        "probs = tf.nn.softmax(predictions).numpy()\n",
        "print(probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.077 0.161 0.082 0.128 0.115 0.065 0.128 0.102 0.084 0.058]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qYP96XQtGyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326f44f9-4e97-496a-87ce-5471c5d90089"
      },
      "source": [
        "# The model makes prediction based on the largest probability\n",
        "class_prediction = np.argmax(probs)\n",
        "print(class_prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVm7q3LxtG1P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9b092945-f21a-4439-ca25-a7ec2a3b1d55"
      },
      "source": [
        "# Visualize this image\n",
        "plt.imshow(x_train[index].reshape([28, 28]), cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff96ac873d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggOzNsa1uwja"
      },
      "source": [
        "The prediction accuracy is low, since no training has been performed yet. Let's introduce a function that measures the prediction error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjzqbX0UtG32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7608b150-886f-4510-fa57-bb38cbafa87d"
      },
      "source": [
        "# Let's introduce a function that measures the prediction error.\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "loss_fn(y_train[index:(index+1)], predictions).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2816932"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw9uDuEytG6Q"
      },
      "source": [
        "# Set up the training environment\n",
        "model.compile(optimizer='adam',\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDobEUh2tG80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48d2fde-a09a-4261-814e-2ce78cddf1c7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ5sa_9jtG_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395e1202-68fe-405c-fc7b-5cbf0cef6343"
      },
      "source": [
        "# The Model.fit method adjusts the model parameters to minimize the loss\n",
        "model.fit(x_train, y_train, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4025 - accuracy: 0.8808\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0938 - accuracy: 0.9714\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0625 - accuracy: 0.9808\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0477 - accuracy: 0.9849\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0385 - accuracy: 0.9873\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff960073390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWwe44uwtHB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46073cd7-90b2-428c-d06b-1e4727c50a94"
      },
      "source": [
        "# The above loss and accuracy is for the training data. Let's evaluate the model on the test set.\n",
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.9767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0805821493268013, 0.9767000079154968]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCUr9uNVvTUd"
      },
      "source": [
        "The image classifier is now trained to ~98% accuracy on this dataset. Let's create a test case ourselves. For example, we can use MS Paint to draw a digit. Remember to resize the canvas to 28*28 pixels\n",
        "\n",
        "Upload the image to Colab environment by clicking the \"Upload to Session Storage\" button in the File tab on the left."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xmz8T3bkvMub",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "08371578-846d-44e2-9921-63fd349fe2dc"
      },
      "source": [
        "# import pillow for image transformation\n",
        "import PIL\n",
        "img = PIL.Image.open(\"test_img.png\")\n",
        "img = img.convert('1') # convert image to black and white\n",
        "print(img.size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-fabc4c13eb0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import pillow for image transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_img.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert image to black and white\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_img.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxfuWEWRwHaH"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65WB0tsVwIst"
      },
      "source": [
        "# What values are contained in img by default?\n",
        "img_processed = np.asarray(img).astype(float)\n",
        "plt.imshow(img_processed, cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE0UFrnowKjP"
      },
      "source": [
        "# Switch black and white values\n",
        "img_np = 1 - np.asarray(img).astype(float)\n",
        "plt.imshow(img_np, cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_w9L9LiwwPVR"
      },
      "source": [
        "# Obtain predictions from the model\n",
        "raw_prediction = model(img_np.reshape([-1, 28, 28]))\n",
        "print(raw_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wddvr0JhwQ6L"
      },
      "source": [
        "# Convert the output into a numpy array\n",
        "predictions = raw_prediction.numpy()\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0CXGSIBwSVv"
      },
      "source": [
        "# Convert the raw outputs (logits) into probabilities\n",
        "probs = tf.nn.softmax(predictions).numpy()\n",
        "print(probs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqFIRbtywUsb"
      },
      "source": [
        "class_prediction = np.argmax(probs)\n",
        "print(class_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86aDkvT_wX-A"
      },
      "source": [
        "# Show the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfdJJBhwwcc5"
      },
      "source": [
        "# y_test_pred = np.argmax(model(x_test).numpy())\n",
        "y_test_pred = []\n",
        "raw_predictions = model(x_test).numpy()\n",
        "for row_idx in range(raw_predictions.shape[0]):\n",
        "    logits = raw_predictions[row_idx, :]\n",
        "    probs = tf.nn.softmax(logits).numpy()\n",
        "    class_pred = np.argmax(probs)\n",
        "    y_test_pred.append(class_pred)\n",
        "print(y_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQlr63xZwddk"
      },
      "source": [
        "mat = confusion_matrix(y_test, y_test_pred)\n",
        "print(mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBME1_pWwgpF"
      },
      "source": [
        "# Exercise: Are larger models better?\n",
        "Modify the neural network model in one of the following ways:\n",
        "1. Increate the number of neurons from 128 to 256.\n",
        "2. Add another layer of 128 nodes.\n",
        "Report the accuracy and the confusion matrix on the test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYK9R4qGycA-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}